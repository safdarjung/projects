{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "nbZC0tXJnbNG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)"
      ],
      "metadata": {
        "id": "SG9yRY47MN4e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qn3yZkhaNJff",
        "outputId": "3421022f-76e1-4514-e081-19b66756466b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./datasets/flower_photos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pathlib   # pathlib is used mainly for doing operations on path of a file or in a file or directory like\n",
        "                 # fetching the files from a directory with only .txt/.jpeg extensions\n",
        "data_dir=pathlib.Path(data_dir)\n",
        "data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgTTtAWuN6Gg",
        "outputId": "2f6952e8-cbae-4d45-80c9-58b48ff81d45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(data_dir.glob('*/*.jpg')))\n",
        "'''You can also use the ** pattern to perform a recursive search through subdirectories.\n",
        " For example, if you want to find all text files in the specified directory and its subdirectories, you can use .glob(\"**/*.txt\")\n",
        " '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ccIFaKHBOMxO",
        "outputId": "49850729-0479-460b-8ba3-17e80249fd4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You can also use the ** pattern to perform a recursive search through subdirectories.\\n For example, if you want to find all text files in the specified directory and its subdirectories, you can use .glob(\"**/*.txt\")\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flower_images_dict ={\n",
        "    'roses':list(data_dir.glob('roses/*')),\n",
        "    'tulips':list(data_dir.glob('tulips/*')),\n",
        "    'dandelion':list(data_dir.glob('dandelion/*')),\n",
        "    'sunflower':list(data_dir.glob('sunflower/*')),\n",
        "    'daisy':list(data_dir.glob('daisy/*')),\n",
        "}"
      ],
      "metadata": {
        "id": "2w-P2XZPQgrk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flower_labels_dict={\n",
        "    'roses':0,\n",
        "    'tulips':1,\n",
        "    'dandelion':2,\n",
        "    'sunflower':3,\n",
        "    'daisy':4\n",
        "}"
      ],
      "metadata": {
        "id": "Au8huL0ER5mx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv2.imread(str(flower_images_dict['roses'][0]))\n",
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWvNOKONR68A",
        "outputId": "93336751-a397-42f9-f698-b9cccb5aa402"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(333, 500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=[],[]\n",
        "for flower_name, images in flower_images_dict.items():\n",
        "  for image in images:\n",
        "    img=cv2.imread(str(image))\n",
        "    resized_img=cv2.resize(img,(224,224))\n",
        "    x.append(resized_img)\n",
        "    y.append(flower_labels_dict[flower_name])"
      ],
      "metadata": {
        "id": "EqoRQRubSumY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "5aRu31-5TjH5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42)"
      ],
      "metadata": {
        "id": "CewXSjRwVE9S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9zG4UcZVZBd",
        "outputId": "a9682e81-873f-410b-d7b2-7a56a526bbeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2228, 224, 224, 3)\n",
            "(2228,)\n",
            "(743, 224, 224, 3)\n",
            "(743,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling\n",
        "X_train_scaled=x_train/255\n",
        "y_train_scaled=y_train/255\n",
        "x_test_scaled=x_test/255\n",
        "y_test_scaled=y_test/255"
      ],
      "metadata": {
        "id": "hpgYdaFCVsyt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "\n",
        "# data_augmentation = keras.Sequential(\n",
        "#   [\n",
        "#     layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
        "#                                                  input_shape=(180,\n",
        "#                                                               180,\n",
        "#                                                               3)),\n",
        "#     layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "#     layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "#   ]\n",
        "# )\n",
        "\n",
        "# model = Sequential([\n",
        "#     data_augmentation,\n",
        "#     layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "#     layers.MaxPooling2D(),\n",
        "#     layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "#     layers.MaxPooling2D(),\n",
        "#     layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#     layers.MaxPooling2D(),\n",
        "#     layers.Dropout(0.2),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(128, activation='relu'),\n",
        "#     layers.Dense(num_classes,activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(X_train_scaled, y_train, epochs=30)\n"
      ],
      "metadata": {
        "id": "nc-faMtvWEVW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  model.evaluate(x_test_scaled,y_test)\n",
        "#  # overfitting - data augmentation"
      ],
      "metadata": {
        "id": "yIkwDHawXw8k"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now using transfer learning training the same model, using mobilnet_v2 classification model\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import PIL.Image as Image\n",
        "\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "classifier = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
        "])"
      ],
      "metadata": {
        "id": "s4cS4OVbbWWK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_labels=[]\n",
        "\n",
        "with open('ImageNetLabels.txt','r') as f:\n",
        "  image_labels = f.read().splitlines()\n",
        "image_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJwVKMnbiuQm",
        "outputId": "9b3be1c4-f287-4ea6-f249-3490ab00479d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['background', 'tench', 'goldfish', 'great white shark', 'tiger shark']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted= classifier.predict(np.array([x[0],x[1],x[2],x[3],x[4]]))\n",
        "predicted=np.argmax(predicted,axis=1)\n",
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOfK0IRGoHgB",
        "outputId": "ddb169cd-fd85-412b-98db-d3da988dde2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([795, 795, 722, 795, 795])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_labels[795],image_labels[722])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZcFsaZbsArj",
        "outputId": "21a815c8-adc5-483d-9035-25dae8b8c76b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shower curtain pillow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(x[0])"
      ],
      "metadata": {
        "id": "C1fTknlYsQNZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(x[1])"
      ],
      "metadata": {
        "id": "Uf0WcErYsaqw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(x[2])"
      ],
      "metadata": {
        "id": "0iyslL3BscDj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_model=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "pretrained_model_wo_top_layer = hub.KerasLayer(\n",
        "    feature_extractor_model,input_shape=(224,224,3), trainable=False\n",
        ")"
      ],
      "metadata": {
        "id": "B-ubYeJWsexB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= tf.keras.Sequential([\n",
        "    pretrained_model_wo_top_layer,\n",
        "    tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41WwW6NftaMb",
        "outputId": "53c6b562-136a-4c4d-d231-69f39608e8d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 6405      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2264389 (8.64 MB)\n",
            "Trainable params: 6405 (25.02 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(X_train_scaled, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLDX2NzAt_HY",
        "outputId": "e9ed9cc2-164c-4060-dde9-eb71650c09e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "70/70 [==============================] - 9s 50ms/step - loss: 0.7487 - accuracy: 0.7096\n",
            "Epoch 2/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.3564 - accuracy: 0.8703\n",
            "Epoch 3/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.2827 - accuracy: 0.9071\n",
            "Epoch 4/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.2341 - accuracy: 0.9237\n",
            "Epoch 5/10\n",
            "70/70 [==============================] - 3s 42ms/step - loss: 0.2094 - accuracy: 0.9331\n",
            "Epoch 6/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.1778 - accuracy: 0.9475\n",
            "Epoch 7/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.1614 - accuracy: 0.9560\n",
            "Epoch 8/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.1424 - accuracy: 0.9650\n",
            "Epoch 9/10\n",
            "70/70 [==============================] - 3s 42ms/step - loss: 0.1285 - accuracy: 0.9663\n",
            "Epoch 10/10\n",
            "70/70 [==============================] - 3s 41ms/step - loss: 0.1196 - accuracy: 0.9708\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d9ef0abdd80>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D26xWw0ueQO",
        "outputId": "18b4b562-34ff-43a8-de03-cf63efbcfc80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 59ms/step - loss: 0.2685 - accuracy: 0.9004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2684653103351593, 0.9004037976264954]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7uR4kzwxRUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}